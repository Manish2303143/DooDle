{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>569934458364813313</td>\n",
       "      <td>neutral</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cottopanama85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir followback</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 10:58:58 -0800</td>\n",
       "      <td>ohio,panama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>568564006329434113</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaulBEsteves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united thanks for the help. Wish the phone re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 16:13:17 -0800</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>569643648910028801</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>runfixsteve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 15:43:24 -0800</td>\n",
       "      <td>St. Augustine, Florida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>568864981917110272</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLChicosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 12:09:15 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>568929299350179840</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JW_Blocker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@united you are by far the worst airline. 4 pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:24:49 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment     airline  \\\n",
       "0      567900433542488064          negative   Southwest   \n",
       "1      569989168903819264          positive   Southwest   \n",
       "2      568089179520954368          positive      United   \n",
       "3      568928195581513728          negative   Southwest   \n",
       "4      568594180014014464          negative      United   \n",
       "...                   ...               ...         ...   \n",
       "10975  569934458364813313           neutral    American   \n",
       "10976  568564006329434113          positive      United   \n",
       "10977  569643648910028801          negative  US Airways   \n",
       "10978  568864981917110272          negative  US Airways   \n",
       "10979  568929299350179840          negative      United   \n",
       "\n",
       "      airline_sentiment_gold           name negativereason_gold  \\\n",
       "0                        NaN  ColeyGirouard                 NaN   \n",
       "1                        NaN  WalterFaddoul                 NaN   \n",
       "2                        NaN      LocalKyle                 NaN   \n",
       "3                        NaN    amccarthy19                 NaN   \n",
       "4                        NaN        J_Okayy                 NaN   \n",
       "...                      ...            ...                 ...   \n",
       "10975                    NaN  Cottopanama85                 NaN   \n",
       "10976                    NaN   PaulBEsteves                 NaN   \n",
       "10977                    NaN    runfixsteve                 NaN   \n",
       "10978                    NaN     CLChicosky                 NaN   \n",
       "10979                    NaN     JW_Blocker                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0  @SouthwestAir I am scheduled for the morning, ...   \n",
       "1                  0  @SouthwestAir seeing your workers time in and ...   \n",
       "2                  0  @united Flew ORD to Miami and back and  had gr...   \n",
       "3                  0     @SouthwestAir @dultch97 that's horse radish üò§üê¥   \n",
       "4                  0  @united so our flight into ORD was delayed bec...   \n",
       "...              ...                                                ...   \n",
       "10975              0                            @AmericanAir followback   \n",
       "10976              0  @united thanks for the help. Wish the phone re...   \n",
       "10977              0  @usairways the. Worst. Ever. #dca #customerser...   \n",
       "10978              0  @nrhodes85: look! Another apology. DO NOT FLY ...   \n",
       "10979              1  @united you are by far the worst airline. 4 pl...   \n",
       "\n",
       "      tweet_coord              tweet_created              tweet_location  \\\n",
       "0             NaN  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1             NaN  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2             NaN  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3             NaN  2015-02-20 16:20:26 -0800                         NaN   \n",
       "4             NaN  2015-02-19 18:13:11 -0800                         NaN   \n",
       "...           ...                        ...                         ...   \n",
       "10975         NaN  2015-02-23 10:58:58 -0800                 ohio,panama   \n",
       "10976         NaN  2015-02-19 16:13:17 -0800                    Brooklyn   \n",
       "10977         NaN  2015-02-22 15:43:24 -0800      St. Augustine, Florida   \n",
       "10978         NaN  2015-02-20 12:09:15 -0800                         NaN   \n",
       "10979         NaN  2015-02-20 16:24:49 -0800                         NaN   \n",
       "\n",
       "                    user_timezone  \n",
       "0          Atlantic Time (Canada)  \n",
       "1      Central Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3          Atlantic Time (Canada)  \n",
       "4      Eastern Time (US & Canada)  \n",
       "...                           ...  \n",
       "10975                         NaN  \n",
       "10976  Eastern Time (US & Canada)  \n",
       "10977                         NaN  \n",
       "10978                         NaN  \n",
       "10979                         NaN  \n",
       "\n",
       "[10980 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database=pd.read_csv(\"train.csv\")\n",
    "document=database.text.values\n",
    "target=database.airline_sentiment.values\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words=[word_tokenize(w) for w in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop=[[words for words in w if words not in stopwords.words(\"english\")] for w in tokenized_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pun=[[words for words in w if words not in string.punctuation] for w in no_stop]\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "clean_doc=[]\n",
    "for i in range(len(no_pun)):\n",
    "    words=TreebankWordDetokenizer().detokenize(no_pun[i])\n",
    "    clean_doc.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 1, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(max_features=10,ngram_range=(1,2))\n",
    "train_data=vectorizer.fit_transform(clean_doc)\n",
    "train_data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]\n",
    "for i in range(len(target)):\n",
    "    if target[i]==\"negative\":\n",
    "        y_train.append(0)\n",
    "    if target[i]==\"neutral\":\n",
    "        y_train.append(1)\n",
    "    if target[i]==\"positive\":\n",
    "        y_train.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=SVC()\n",
    "clf.fit(train_data,y_train)\n",
    "x_test_pd=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_document=x_test_pd.text.values\n",
    "tokenized_words_t=[word_tokenize(w) for w in test_document]\n",
    "no_stop_t=[[words for words in w if words not in stopwords.words(\"english\")] for w in tokenized_words_t]\n",
    "no_pun_t=[[words for words in w if words not in string.punctuation] for w in no_stop_t]\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "clean_doc_t=[]\n",
    "for i in range(len(no_pun_t)):\n",
    "    words=TreebankWordDetokenizer().detokenize(no_pun_t[i])\n",
    "    clean_doc_t.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_t=CountVectorizer(max_features=10,ngram_range=(1,2))\n",
    "test_data=vectorizer.fit_transform(clean_doc_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'neutral', 'negative',\n",
       "       'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=clf.predict(test_data)\n",
    "clf.score(train_data,y_train)\n",
    "y_predict_text=[]\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i]==0:\n",
    "        y_predict_text.append(\"negative\")\n",
    "    if y_predict[i]==1:\n",
    "        y_predict_text.append(\"neutral\")\n",
    "    if y_predict[i]==2:\n",
    "        y_predict_text.append(\"positive\")\n",
    "y_predict_np=np.array(y_predict_text)\n",
    "y_predict_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"submit.csv\",y_predict_np,fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
